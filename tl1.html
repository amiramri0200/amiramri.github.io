<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Massively by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/atom-one-dark.min.css">

		<script src="https://cdn.jsdelivr.net/npm/highlightjs-line-numbers.js@2.8.0/dist/highlightjs-line-numbers.min.js"></script>
	
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">


				<!-- Header -->
					<header id="header">
						<a href="machinelearning.html" class="logo">ML Projects</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li class="active"><a href="machinelearning.html">ML Project - NN/CNN</a></li>
						</ul>
						<ul class="icons">
							<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
							<li><a href="#" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						During the course Numerical Optimization Mehtod I develope an Implemention of a number of Optimization algorithms.<br>
						<h3>Newton Method</h3>
						<!-- Featured Post -->
						Newton's optimization method, is an iterative numerical technique used for optimizing a function to find its minimum or maximum.

The method is based on the idea of using local linear approximations to iteratively approach the root or extremum of a function. Starting with an initial guess, the algorithm updates the guess by considering the slope (derivative) and curvature (second derivative) of the function at the current point. 
<br> In this Project This optimization method is implemented in Matlab.
<h3>BFGS & Linesearch</h3>
BFGS is a widely used iterative optimization algorithm designed to find the minimum of a differentiable, scalar-valued function. Unlike Newton's method, BFGS does not require the calculation of second derivatives (Hessian matrix) and is particularly well-suited for large-scale optimization problems.

The primary idea behind BFGS is to iteratively update an approximation of the inverse Hessian matrix, which is used to direct the search for the minimum. The algorithm maintains an estimate of the Hessian's inverse throughout the iterations, adjusting it based on the gradient information obtained from the function. 
<br>

Line search is a critical component of optimization algorithms like BFGS. After obtaining a search direction from the inverse Hessian approximation, a line search is performed to determine the step size along that direction. The goal is to find the step size that minimizes the objective function along the search direction.

In a nutshell, the BFGS algorithm iteratively refines its estimate of the inverse Hessian matrix and
 performs a line search to determine the step size along the search direction.
  This combination of updates and line search helps efficiently navigate the parameter space toward the optimal solution.
						<br><b><a href="https://github.com/amiramri0200/machineLearningProjects/tree/main/ML1" style="color: rgb(239, 111, 7)">HERE</a></b> you can see the source code of the project and results.
						
					</div>
					<!--	<pre>
							<code>!pip install optuna
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader,random_split, SubsetRandomSampler
from torchvision import transforms
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
import torch.nn.functional as F
from sklearn.model_selection import train_test_split
import optuna</code>
						</pre>
						 Footer -->
							<footer>
								
							</footer>

					</div>

				<!-- Footer -->
					

				<!-- Copyright -->
					<div id="copyright">
						
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
			<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
			<script>hljs.highlightAll();</script>
			<script>
				hljs.
			</script>
	</body>
</html>